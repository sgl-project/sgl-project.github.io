
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Supported Models &#8212; SGLang</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=731335ad" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=731335ad" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=bb509808"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=ccdb6887"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'references/supported_models';</script>
    <link rel="icon" href="../_static/logo.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Contribution Guide" href="contribution_guide.html" />
    <link rel="prev" title="General Guidance" href="general.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="0.4.4.post1" />
    <meta name="docbuild:last-update" content="Mar 25, 2025"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="SGLang - Home"/>
    <img src="../_static/logo.png" class="logo__image only-dark pst-js-only" alt="SGLang - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../start/install.html">Install SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Backend Tutorial</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="deepseek.html">DeepSeek Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/send_request.html">Sending Requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/openai_api_completions.html">OpenAI APIs - Completions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/openai_api_vision.html">OpenAI APIs - Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/openai_api_embeddings.html">OpenAI APIs - Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/native_api.html">SGLang Native APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/offline_engine_api.html">Offline Engine API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/server_arguments.html">Server Arguments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/sampling_params.html">Sampling Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/hyperparameter_tuning.html">Hyperparameter Tuning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../backend/speculative_decoding.html">Speculative Decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/structured_outputs.html">Structured Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/function_calling.html">Tool and Function Calling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/separate_reasoning.html">Reasoning Parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/custom_chat_template.html">Custom Chat Template</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/quantization.html">Quantization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Frontend Tutorial</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../frontend/frontend.html">SGLang Frontend Language</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frontend/choices_methods.html">Choices Methods in SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">SGLang Router</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../router/router.html">Router for Data Parallelism</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="general.html">General Guidance</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Supported Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="contribution_guide.html">Contribution Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="learn_more.html">Learn more</a></li>
<li class="toctree-l2"><a class="reference internal" href="modelscope.html">Use Models From ModelScope</a></li>
<li class="toctree-l2"><a class="reference internal" href="production_metrics.html">Production Metrics</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="hardware.html">Hardware Supports</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_deploy.html">Multi-Node Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_tuning.html">Performance Tuning</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/blob/main/references/supported_models.md?plain=1" target="_blank"
   class="btn btn-sm btn-source-file-button dropdown-item"
   title="Show source"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">Show source</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/edit/main/references/supported_models.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/issues/new?title=Issue%20on%20page%20%2Freferences/supported_models.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/references/supported_models.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Supported Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-models">Generative Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embedding-models">Embedding Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reward-models">Reward Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-support-a-new-language-model">How to Support a New Language Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-support-a-new-vlm">How to Support a New vLM</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#test-the-correctness">Test the correctness</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-debugging">Interactive debugging</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#add-the-model-to-the-test-suite">Add the model to the test suite</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#port-a-model-from-vllm-to-sglang">Port a model from vLLM to SGLang</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#registering-an-external-model-implementation">Registering an external model implementation</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="supported-models">
<h1>Supported Models<a class="headerlink" href="#supported-models" title="Link to this heading">#</a></h1>
<section id="generative-models">
<h2>Generative Models<a class="headerlink" href="#generative-models" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Llama / Llama 2 / Llama 3 / Llama 3.1 / Llama 3.2 / Llama 3.3</p></li>
<li><p>Mistral / Mixtral / Mistral NeMo / Mistral Small 3</p></li>
<li><p>Gemma / Gemma 2 / Gemma3</p></li>
<li><p>Qwen / Qwen 2 / Qwen 2 MoE / Qwen 2 VL / Qwen 2.5 VL</p></li>
<li><p>DeepSeek / DeepSeek 2 / <a class="reference external" href="https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3">DeepSeek 3</a></p></li>
<li><p>OLMoE</p></li>
<li><p><a class="reference external" href="https://llava-vl.github.io/blog/2024-08-05-llava-onevision/">LLaVA-OneVision</a></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">-m</span> <span class="pre">sglang.launch_server</span> <span class="pre">--model-path</span> <span class="pre">lmms-lab/llava-onevision-qwen2-7b-ov</span> <span class="pre">--port=30000</span> <span class="pre">--chat-template=chatml-llava</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">-m</span> <span class="pre">sglang.launch_server</span> <span class="pre">--model-path</span> <span class="pre">lmms-lab/llava-onevision-qwen2-72b-ov</span> <span class="pre">--port=30000</span> <span class="pre">--tp-size=8</span> <span class="pre">--chat-template=chatml-llava</span></code></p></li>
<li><p>Query the server with the <a class="reference external" href="https://platform.openai.com/docs/guides/vision">OpenAI Vision API</a>. See examples at <a class="reference external" href="https://github.com/sgl-project/sglang/blob/main/test/srt/test_vision_openai_server.py">test/srt/test_vision_openai_server.py</a></p></li>
</ul>
</li>
<li><p>LLaVA 1.5 / 1.6 / NeXT</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">sglang.launch_server</span> <span class="pre">--model-path</span> <span class="pre">lmms-lab/llama3-llava-next-8b</span> <span class="pre">--port=30000</span> <span class="pre">--tp-size=1</span> <span class="pre">--chat-template=llava_llama_3</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">sglang.launch_server</span> <span class="pre">--model-path</span> <span class="pre">lmms-lab/llava-next-72b</span> <span class="pre">--port=30000</span> <span class="pre">--tp-size=8</span> <span class="pre">--chat-template=chatml-llava</span></code></p></li>
<li><p>Query the server with the <a class="reference external" href="https://platform.openai.com/docs/guides/vision">OpenAI Vision API</a>. See examples at <a class="reference external" href="https://github.com/sgl-project/sglang/blob/main/test/srt/test_vision_openai_server.py">test/srt/test_vision_openai_server.py</a></p></li>
</ul>
</li>
<li><p>Yi-VL</p></li>
<li><p>StableLM</p></li>
<li><p>Command-R</p></li>
<li><p>DBRX</p></li>
<li><p>Grok</p></li>
<li><p>ChatGLM</p></li>
<li><p>InternLM 2</p></li>
<li><p>Exaone 3</p></li>
<li><p>BaiChuan2</p></li>
<li><p>MiniCPM / MiniCPM 3 / MiniCPM-v / MiniCPM-o</p></li>
<li><p>XVERSE / XVERSE MoE</p></li>
<li><p>SmolLM</p></li>
<li><p>GLM-4</p></li>
<li><p>Phi-3 / Phi-4</p></li>
<li><p>Phi-3-Small</p></li>
<li><p>IBM Granite 3</p></li>
<li><p>Janus-Pro-1B / Janus-Pro-7B</p></li>
<li><p>Deepseek-VL2 / Deepseek-VL2-small</p></li>
<li><p>Gemma 3 (it)</p></li>
</ul>
</section>
<section id="embedding-models">
<h2>Embedding Models<a class="headerlink" href="#embedding-models" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>LlamaEmbeddingModel</p></li>
<li><p>Mistral embedding models</p></li>
<li><p>Qwen embedding models</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">sglang.launch_server</span> <span class="pre">--model-path</span> <span class="pre">Alibaba-NLP/gte-Qwen2-7B-instruct</span> <span class="pre">--is-embedding</span></code></p></li>
</ul>
</li>
<li><p>Multi-modal embedding models</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">sglang.launch_server</span> <span class="pre">--model-path</span> <span class="pre">Alibaba-NLP/gme-Qwen2-VL-2B-Instruct</span> <span class="pre">--is-embedding</span> <span class="pre">--chat-template</span> <span class="pre">gme-qwen2-vl</span></code></p></li>
</ul>
</li>
</ul>
</section>
<section id="reward-models">
<h2>Reward Models<a class="headerlink" href="#reward-models" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>LlamaForSequenceClassification</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">sglang.launch_server</span> <span class="pre">--model-path</span> <span class="pre">Skywork/Skywork-Reward-Llama-3.1-8B-v0.2</span> <span class="pre">--is-embedding</span></code></p></li>
</ul>
</li>
<li><p>Gemma2ForSequenceClassification</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">sglang.launch_server</span> <span class="pre">--model-path</span> <span class="pre">Skywork/Skywork-Reward-Gemma-2-27B-v0.2</span> <span class="pre">--is-embedding</span></code></p></li>
</ul>
</li>
<li><p>InternLM2ForRewardModel</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">sglang.launch_server</span> <span class="pre">--model-path</span> <span class="pre">internlm/internlm2-7b-reward</span> <span class="pre">--is-embedding</span> <span class="pre">--trust-remote-code</span></code></p></li>
</ul>
</li>
<li><p>Qwen2ForRewardModel</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">sglang.launch_server</span> <span class="pre">--model-path</span> <span class="pre">Qwen/Qwen2.5-Math-RM-72B</span> <span class="pre">--is-embedding</span> <span class="pre">--trust-remote-code</span> <span class="pre">--tp-size=4</span></code></p></li>
</ul>
</li>
<li><p>Qwen2ForSequenceClassification</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">sglang.launch_server</span> <span class="pre">--model-path</span> <span class="pre">jason9693/Qwen2.5-1.5B-apeach</span> <span class="pre">--is-embedding</span> <span class="pre">--trust-remote-code</span></code></p></li>
</ul>
</li>
</ul>
</section>
<section id="how-to-support-a-new-language-model">
<h2>How to Support a New Language Model<a class="headerlink" href="#how-to-support-a-new-language-model" title="Link to this heading">#</a></h2>
<p>To support a new model in SGLang, you only need to add a single file under <a class="reference external" href="https://github.com/sgl-project/sglang/tree/main/python/sglang/srt/models">SGLang Models Directory</a>.
You can learn from existing model implementations and create new files for the new models.
For most models, you should be able to find a similar model to start with (e.g., starting from Llama).</p>
</section>
<section id="how-to-support-a-new-vlm">
<h2>How to Support a New vLM<a class="headerlink" href="#how-to-support-a-new-vlm" title="Link to this heading">#</a></h2>
<p>To support a new vision-language model (vLM) in SGLang, there are several key components in addition to the standard
LLM.</p>
<ol class="arabic simple">
<li><p><strong>Register your new model as multimodal</strong>: Extend <code class="docutils literal notranslate"><span class="pre">is_multimodal_model</span></code> in <a class="reference external" href="https://github.com/sgl-project/sglang/blob/main/python/sglang/srt/configs/model_config.py">
<code class="docutils literal notranslate"><span class="pre">model_config.py</span></code></a> to
return True for your model.</p></li>
<li><p><strong>Process Images</strong>: Define a new <code class="docutils literal notranslate"><span class="pre">Processor</span></code> class that inherits from <code class="docutils literal notranslate"><span class="pre">BaseProcessor</span></code> and register this
processor as your model’s dedicated processor. See <a class="reference external" href="https://github.com/sgl-project/sglang/blob/main/python/sglang/srt/managers/multimodal_processor.py">
<code class="docutils literal notranslate"><span class="pre">multimodal_processor.py</span></code></a>
for more details.</p></li>
<li><p><strong>Handle Image Tokens</strong>: Implement a <code class="docutils literal notranslate"><span class="pre">pad_input_ids</span></code> function for your new model, in which image tokens in the prompt
should be expanded and replaced with image-hashes, so that SGLang can recognize different images for
<code class="docutils literal notranslate"><span class="pre">RadixAttention</span></code>.</p></li>
<li><p>Replace Multi-headed <code class="docutils literal notranslate"><span class="pre">Attention</span></code> of ViT with SGLang’s <code class="docutils literal notranslate"><span class="pre">VisionAttention</span></code>.</p></li>
</ol>
<p>You can refer <a class="reference external" href="https://github.com/sgl-project/sglang/blob/main/python/sglang/srt/models/qwen2_vl.py">Qwen2VL</a> or other
vLMs. These models demonstrate how to properly handle both multimodal and textual inputs.</p>
<p>You should test the new vLM locally against hf models. See <a class="reference external" href="https://github.com/sgl-project/sglang/tree/main/benchmark/mmmu"><code class="docutils literal notranslate"><span class="pre">mmmu</span></code></a> for an example.</p>
<section id="test-the-correctness">
<h3>Test the correctness<a class="headerlink" href="#test-the-correctness" title="Link to this heading">#</a></h3>
<section id="interactive-debugging">
<h4>Interactive debugging<a class="headerlink" href="#interactive-debugging" title="Link to this heading">#</a></h4>
<p>For interactive debugging, you can compare the outputs of huggingface/transformers and SGLang.
The following two commands should give the same text output and very similar prefill logits.</p>
<ul class="simple">
<li><p>Get the reference output by <code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">scripts/playground/reference_hf.py</span> <span class="pre">--model-path</span> <span class="pre">[new</span> <span class="pre">model]</span> <span class="pre">--model-type</span> <span class="pre">{text,vlm}</span></code></p></li>
<li><p>Get the SGLang output by <code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">-m</span> <span class="pre">sglang.bench_one_batch</span> <span class="pre">--correct</span> <span class="pre">--model</span> <span class="pre">[new</span> <span class="pre">model]</span></code></p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When comparing outputs between reference_hf.py and SGLang, ensure that parameters such as <code class="docutils literal notranslate"><span class="pre">--dtype</span></code>, temperature, top_p, and other sampling parameters are identical across both scripts. Even small differences in these parameters can lead to variations in output that might be mistakenly attributed to implementation issues.</p>
</div>
</section>
<section id="add-the-model-to-the-test-suite">
<h4>Add the model to the test suite<a class="headerlink" href="#add-the-model-to-the-test-suite" title="Link to this heading">#</a></h4>
<p>To make sure the new model is well maintained in the future, it is better to add it to the test suite.
You can add it to the <code class="docutils literal notranslate"><span class="pre">ALL_OTHER_MODELS</span></code> list in the <a class="reference external" href="https://github.com/sgl-project/sglang/blob/main/test/srt/models/test_generation_models.py">test_generation_models.py</a> and run the following command to test it.</p>
<p>For example, if the model is Qwen/Qwen2-1.5B</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ONLY_RUN</span><span class="o">=</span><span class="n">Qwen</span><span class="o">/</span><span class="n">Qwen2</span><span class="o">-</span><span class="mf">1.5</span><span class="n">B</span> <span class="n">python3</span> <span class="o">-</span><span class="n">m</span> <span class="n">unittest</span> <span class="n">test_generation_models</span><span class="o">.</span><span class="n">TestGenerationModels</span><span class="o">.</span><span class="n">test_others</span>
</pre></div>
</div>
</section>
</section>
<section id="port-a-model-from-vllm-to-sglang">
<h3>Port a model from vLLM to SGLang<a class="headerlink" href="#port-a-model-from-vllm-to-sglang" title="Link to this heading">#</a></h3>
<p>Another valuable resource is the <a class="reference external" href="https://github.com/vllm-project/vllm/tree/main/vllm/model_executor/models">vLLM Models Directory</a>. vLLM has extensive coverage of models, and SGLang reuses vLLM’s interface and some layers to implement the models. This similarity makes it easy to port many models from vLLM to SGLang.</p>
<p>To port a model from vLLM to SGLang, you can compare these two files <a class="reference external" href="https://github.com/sgl-project/sglang/blob/main/python/sglang/srt/models/llama.py">SGLang Llama Implementation</a> and <a class="reference external" href="https://github.com/vllm-project/vllm/blob/main/vllm/model_executor/models/llama.py">vLLM Llama Implementation</a>. This comparison will help you understand how to convert a model implementation from vLLM to SGLang. The major difference is the replacement of Attention with RadixAttention. The other parts are almost identical. Specifically,</p>
<ul class="simple">
<li><p>Replace vllm’s <code class="docutils literal notranslate"><span class="pre">Attention</span></code> with <code class="docutils literal notranslate"><span class="pre">RadixAttention</span></code>. Note that you need to pass <code class="docutils literal notranslate"><span class="pre">layer_id</span></code> all the way to <code class="docutils literal notranslate"><span class="pre">RadixAttention</span></code>.</p></li>
<li><p>Replace vllm’s <code class="docutils literal notranslate"><span class="pre">LogitsProcessor</span></code> with SGLang’s <code class="docutils literal notranslate"><span class="pre">LogitsProcessor</span></code>.</p></li>
<li><p>Replace Multi-headed <code class="docutils literal notranslate"><span class="pre">Attention</span></code> of ViT with SGLang’s <code class="docutils literal notranslate"><span class="pre">VisionAttention</span></code>.</p></li>
<li><p>Replace other vLLM layers with SGLang layers (e.g., <code class="docutils literal notranslate"><span class="pre">RMSNorm</span></code>, <code class="docutils literal notranslate"><span class="pre">SiluAndMul</span></code>).</p></li>
<li><p>Remove <code class="docutils literal notranslate"><span class="pre">Sample</span></code>.</p></li>
<li><p>Change <code class="docutils literal notranslate"><span class="pre">forward()</span></code> functions, and add <code class="docutils literal notranslate"><span class="pre">forward_batch</span></code>.</p></li>
<li><p>Add <code class="docutils literal notranslate"><span class="pre">EntryClass</span></code> at the end.</p></li>
<li><p>Please ensure the new implementation uses <strong>only SGLang components and does not rely on any vLLM components</strong>.</p></li>
</ul>
</section>
<section id="registering-an-external-model-implementation">
<h3>Registering an external model implementation<a class="headerlink" href="#registering-an-external-model-implementation" title="Link to this heading">#</a></h3>
<p>In addition to the methods described above, you can also register your new model with the <code class="docutils literal notranslate"><span class="pre">ModelRegistry</span></code> before launching the server. This approach is useful if you want to integrate your model without needing to modify the source code.</p>
<p>Here is how you can do it:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.models.registry</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelRegistry</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.entrypoints.http_server</span><span class="w"> </span><span class="kn">import</span> <span class="n">launch_server</span>

<span class="c1"># for a single model, you can add it to the registry</span>
<span class="n">ModelRegistry</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_class</span>

<span class="c1"># for multiple models, you can imitate the import_model_classes() function in sglang/srt/models/registry.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">lru_cache</span>

<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">import_new_model_classes</span><span class="p">():</span>
    <span class="n">model_arch_name_to_cls</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">model_arch_name_to_cls</span>

<span class="n">ModelRegistry</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">import_new_model_classes</span><span class="p">())</span>

<span class="n">launch_server</span><span class="p">(</span><span class="n">server_args</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="general.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">General Guidance</p>
      </div>
    </a>
    <a class="right-next"
       href="contribution_guide.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Contribution Guide</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-models">Generative Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embedding-models">Embedding Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reward-models">Reward Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-support-a-new-language-model">How to Support a New Language Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-support-a-new-vlm">How to Support a New vLM</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#test-the-correctness">Test the correctness</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-debugging">Interactive debugging</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#add-the-model-to-the-test-suite">Add the model to the test suite</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#port-a-model-from-vllm-to-sglang">Port a model from vLLM to SGLang</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#registering-an-external-model-implementation">Registering an external model implementation</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By SGLang Team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023-2025, SGLang.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on Mar 25, 2025.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
